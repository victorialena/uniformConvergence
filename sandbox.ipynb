{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4929dcba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "\n",
    "import dgl\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from graphregression import *\n",
    "from models import GraphRegression\n",
    "\n",
    "import pdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cd85addc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Args:\n",
    "    num_samples = 1000\n",
    "    batch_size = 64\n",
    "    epochs = 10\n",
    "    num_test_samples = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a090815b",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = Args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d834d1b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "prior = get_prior()\n",
    "\n",
    "model = GraphRegression()\n",
    "dataset = Dataset(args.num_samples, prior)\n",
    "dataloader = dgl.dataloading.GraphDataLoader(dataset, batch_size=args.batch_size, \n",
    "                                             shuffle=True, drop_last=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4b980031",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = torch.optim.Adam(model.parameters())\n",
    "loss_fn = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a739efbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.train(True)\n",
    "for ep in range(args.epochs):\n",
    "    for batched_graph, labels in dataloader:\n",
    "        opt.zero_grad()\n",
    "        \n",
    "        feats = get_normalized_features(batched_graph)\n",
    "        y_hat = model(batched_graph, feats)\n",
    "        loss = loss_fn(y_hat, labels.unsqueeze(-1)) # loss = F.cross_entropy(logits, labels)\n",
    "        loss.backward()\n",
    "        opt.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "543748ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_excess_risk(model, args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3cfc2895",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GraphRegression(\n",
       "  (conv): Sequential(\n",
       "    (0): GraphConv(in=1, out=8, normalization=both, activation=<function relu at 0x7fc7ea720dc0>)\n",
       "    (1): GraphConv(in=8, out=8, normalization=both, activation=None)\n",
       "  )\n",
       "  (readout): Linear(in_features=8, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prior = get_prior()\n",
    "graphs, labels = synthetic_dataset(args.num_test_samples, prior)\n",
    "labels = labels.unsqueeze(-1)\n",
    "model.train(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c90c1138",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.6886, 0.3419, 0.2263, 0.3294, 0.3224, 0.5605, 0.1742, 0.8148, 0.9806,\n",
       "        0.4388])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h_star(batched_graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "427ccbd3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.6310],\n",
       "        [0.3240],\n",
       "        [0.2200],\n",
       "        [0.3210],\n",
       "        [0.3130],\n",
       "        [0.5610],\n",
       "        [0.1580],\n",
       "        [0.8050],\n",
       "        [0.9810],\n",
       "        [0.4400]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b9129091",
   "metadata": {},
   "outputs": [],
   "source": [
    "batched_graph = dgl.batch(graphs)\n",
    "feats = get_normalized_features(batched_graph)\n",
    "y_hat = model(batched_graph, feats)\n",
    "L_hat = F.mse_loss(y_hat, labels)\n",
    "Lstar = F.mse_loss(h_star(batched_graph).unsqueeze(-1), labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "681bc045",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0712, grad_fn=<MseLossBackward0>)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "L_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1096020a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0004)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Lstar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "880d6094",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(5.0737)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model._get_norm()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f5731f4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.4276)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimate_rademacher(model, args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee261173",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_excess_risk(model, args):\n",
    "    prior = get_prior()\n",
    "    graphs, labels = synthetic_dataset(args.num_test_samples, prior)\n",
    "    labels = labels.unsqueeze(-1)\n",
    "    model.train(False)\n",
    "    \n",
    "    batched_graph = dgl.batch(graphs)\n",
    "    feats = get_normalized_features(batched_graph)\n",
    "    y_hat = model(batched_graph, feats)\n",
    "    L_hat = F.mse_loss(y_hat, labels)\n",
    "    Lstar = F.mse_loss(h_star(batched_graph), labels)\n",
    "\n",
    "    return Lstar - L_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74782a3b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dgl",
   "language": "python",
   "name": "dgl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
